{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Uniformity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code replaces all numbers with zeroes. We replace numbers in the title and body text with zero as the specific numerical values are not important, but may add additional noise to the data and may prevent the model from extracting the meaningful features from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_zeroes(df, col):\n",
    "    pattern = re.compile(r'\\d+')\n",
    "    df[col] = df[col].apply(lambda x: re.sub(pattern, '0', x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML Parsing and Separating Natural Language from Programming Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function performs the following processing steps separates text from code blocks, so that they can be passed as separate features to our bimodal NL/PL models. It also cleans the data by removing all HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_code_text(*bodies):\n",
    "    '''\n",
    "    returns: cleaned text, code for each of the body inputs\n",
    "    '''\n",
    "    results = {}\n",
    "    for i, body in enumerate(bodies):\n",
    "        soup = BeautifulSoup(body, \"html.parser\")\n",
    "        blockquotes = soup.find_all(\"blockquote\")\n",
    "        \n",
    "        # remove the duplicate blockquote elements and its contents\n",
    "        for bq in blockquotes:\n",
    "            if \"Duplicate\" in bq:\n",
    "                bq.decompose()\n",
    "\n",
    "        code_blocks = soup.find_all(\"code\")\n",
    "        code = \"\\n\".join([cb.get_text() for cb in code_blocks])\n",
    "        text = soup.get_text()\n",
    "        \n",
    "        results[f\"BodyText{i+1}\"] = text\n",
    "        results[f\"BodyCode{i+1}\"] = code\n",
    "    \n",
    "    return pd.Series(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function removes all indicators that the post has a duplicate, as this would not be present in the real-life test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_blockquote(body_html_1, body_html_2):\n",
    "    '''returns: cleaned body texts'''\n",
    "    soup1 = BeautifulSoup(body_html_1, \"html.parser\")\n",
    "    soup2 = BeautifulSoup(body_html_2, \"html.parser\")\n",
    "\n",
    "    for soup in [soup1, soup2]:\n",
    "        blockquotes = soup.find_all(\"blockquote\")\n",
    "        \n",
    "        # remove the blockquote element and its contents\n",
    "        for bq in blockquotes:\n",
    "            if \"Duplicate\" in bq:\n",
    "                bq.decompose()\n",
    "\n",
    "    return pd.Series({\"Body1\": str(soup1.table), \"Body2\": str(soup2.table)})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Heuristics for Challenging Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a similarity heuristic when selecting non-duplicate posts (negative examples) can help create a more balanced training dataset. Randomly selecting negative examples that are dissimilar to positive examples could result in a biased model. Using a similarity heuristic ensures that non-duplicate posts are similar enough to the duplicate posts to improve the overall accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_heuristic(tags1, tags2):\n",
    "    '''\n",
    "    tags1, tags2 -> both are strings formatted like \"<tagA><tagB><etc>\"\n",
    "    '''\n",
    "    \n",
    "    if not tags1 or not tags2:\n",
    "        return pd.Series({\"Similarity1\": 0, \"Similarity2\": 0})\n",
    "\n",
    "    tags1, tags2 = tags1[1:-1], tags2[1:-1]\n",
    "\n",
    "    set1 = set(tags1.split(\"><\"))\n",
    "    set2 = set(tags2.split(\"><\"))\n",
    "\n",
    "    intersection = set1 & set2\n",
    "    sim1 = len(intersection) / len(set2) if set2 else 0\n",
    "    sim2 = len(intersection) / len(set1) if set1 else 0\n",
    "\n",
    "    return pd.Series({\"Similarity1\": sim1, \"Similarity2\": sim2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sim_heuristic(df, col_1, col_2, threshold=0.5):\n",
    "    df[[\"Similarity1\", \"Similarity2\"]] = df.apply(lambda x: similarity_heuristic(x[col_1], x[col_2]), axis=1)\n",
    "\n",
    "    df_similar_tags = df[(df[col_1] > threshold) & (df[col_2] > threshold)]\n",
    "\n",
    "    return df_similar_tags"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
